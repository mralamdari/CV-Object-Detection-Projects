{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers Recognition's optimal approach(PyTorch).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1hdo9rcA2n6__BYNo3CtccJ6gGIQT7wrO",
      "authorship_tag": "ABX9TyOsyS03lloSQW6PT7FGGrA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/CV-Object-Detection-Projects/blob/main/Flowers_Recognition's_optimal_approach(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hello ðŸ‘‹\n",
        "####This repository will give you a simple approach (but an effective one) to code in PyTorch that can be used recursively for any other problems in Machine Learning/Deep Learning Field.\n",
        "\n",
        "\n",
        "#####Unfortunately, the Ram crushes in the Colab, so I can't train it with PyTorch; if you have more ram, feel free to run this code, but if you don't have a powerful system to run it, you can run this code in [My Kaggle Notebook](https://www.kaggle.com/code/mralamdari/flowers-recognition-s-optimal-approach-PyTorch), there are more models with trainning results in this notebook and you can easily edit and run it.\n",
        "#####You can get more details on this project and learn about object recognition on my article on medium; [How to do Object Recognition with PyTorch(Keras) the Easiest way](https://medium.com/@mr.alamdari/imagehow-to-do-object-recognition-with-PyTorch-keras-the-easiest-way-23c7ab9604c7)"
      ],
      "metadata": {
        "id": "B4InkozPbMUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Import Essential Libraris\n"
      ],
      "metadata": {
        "id": "gJJkAcMiH_uz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-yaX8oXa0Zc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tqdm\n",
        "import torch\n",
        "import warnings\n",
        "import matplotlib\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection, metrics, preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('always')"
      ],
      "metadata": {
        "id": "gIRIdfKebJrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive'\n",
        "!kaggle datasets download -d alxmamaev/flowers-recognition\n",
        "!unzip \\*.zip && rm *.zip"
      ],
      "metadata": {
        "id": "pjO6o3X9bLTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Data\n",
        "The Dataset in this project contains 4242 images of flowers; the data collection is based on the data Flickr, Google Images, and Yandex images, and it is used to recognize plants from the photo. There are five kinds of flowers: daisy, dandelion, rose, sunflower, and tulip, and each class has about 800 pictures of different sizes but not high resolutions. You can access the dataset here."
      ],
      "metadata": {
        "id": "fyw2zXQCZf_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, you can readily do DataAugmentation and grow your dataset's size; since Neural Networks need more data to train, it will enhance the model's performance."
      ],
      "metadata": {
        "id": "2tMuo4SXIJ7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "hDuXm5QEbPhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_folder = '/content/flowers'"
      ],
      "metadata": {
        "id": "eRGf8UhVIa38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = (0.4124234616756439, 0.3674212694168091, 0.2578217089176178)\n",
        "std = (0.3268945515155792, 0.29282665252685547, 0.29053378105163574)"
      ],
      "metadata": {
        "id": "FiNpp5fFIa0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = {\n",
        "    'original': torchvision.transforms.Compose([\n",
        "                                               torchvision.transforms.Resize((115, 115)),\n",
        "                                               torchvision.transforms.ToTensor(),\n",
        "                                               torchvision.transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'dataset1': torchvision.transforms.Compose([\n",
        "                                               torchvision.transforms.Resize((115, 115)),\n",
        "                                               torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                                               torchvision.transforms.RandomRotation(5),\n",
        "                                               torchvision.transforms.RandomAffine(degrees=11, translate=(0.1, 0.1), scale=(0.8, 0.8)),\n",
        "                                               torchvision.transforms.ToTensor(),\n",
        "                                               torchvision.transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'dataset2': torchvision.transforms.Compose([\n",
        "                                               torchvision.transforms.Resize((115, 115)),\n",
        "                                               torchvision.transforms.RandomHorizontalFlip(),\n",
        "                                               torchvision.transforms.RandomRotation(10),\n",
        "                                               torchvision.transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "                                               torchvision.transforms.ToTensor(),\n",
        "                                               torchvision.transforms.RandomErasing(inplace=True, scale=(0.01,  0.23)),\n",
        "                                               torchvision.transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'dataset3': torchvision.transforms.Compose([\n",
        "                                               torchvision.transforms.Resize((115, 115)),\n",
        "                                               torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                               torchvision.transforms.RandomRotation(15),\n",
        "                                               torchvision.transforms.RandomAffine(degrees=11, translate=(0.1, 0.1), scale=(0.8, 0.8)),\n",
        "                                               torchvision.transforms.ToTensor(),\n",
        "                                               torchvision.transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "f0x_YFWsZl-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Test/Val Split"
      ],
      "metadata": {
        "id": "E_bZHpkLIfqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#all dataset ==> train&val + test\n",
        "original = torchvision.datasets.ImageFolder(path, transform=transformer['original'])\n",
        "train_val, test = model_selection.train_test_split(original, test_size=0.2, random_state=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YsWMn0nHZ6i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_val  ==> train + val + dataset1 + dataset2 + dataset3\n",
        "train_val = torch.utils.data.ConcatDataset([train_val,\n",
        "                                torchvision.datasets.ImageFolder(path, transform=transformer['dataset1']),\n",
        "                                torchvision.datasets.ImageFolder(path, transform=transformer['dataset2']),\n",
        "                                torchvision.datasets.ImageFolder(path, transform=transformer['dataset3'])])"
      ],
      "metadata": {
        "id": "X37IoxYBh2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = model_selection.train_test_split(train_val, test_size=0.1, random_state=32, shuffle=True)"
      ],
      "metadata": {
        "id": "EOvQhx0478K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "Kt3DEY_mZhRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32\n",
        "data_loaders = {\n",
        "    'train': torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=2, pin_memory=True),\n",
        "    'val': torch.utils.data.DataLoader(val, batch_size=batch_size, num_workers=2, pin_memory=True),\n",
        "    'test': torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=2, pin_memory=True)\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(train),\n",
        "    'val': len(val),\n",
        "    'test': len(test)\n",
        "}"
      ],
      "metadata": {
        "id": "GKISSfNM79rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes"
      ],
      "metadata": {
        "id": "jX5C031KBziX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How ImBalance is ourdaset"
      ],
      "metadata": {
        "id": "emWpcyMrI_7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic = {}\n",
        "for cls in original.classes:\n",
        "  dic[cls] = len(os.listdir(f'{path}/{cls}'))\n",
        "\n",
        "samplesize = pd.DataFrame(dic, index=[0])\n",
        "samplesize"
      ],
      "metadata": {
        "id": "ryH9H0qt8RMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=samplesize)"
      ],
      "metadata": {
        "id": "vdKBLdj88X-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Visualization"
      ],
      "metadata": {
        "id": "hHW7OcjKIzm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z, _ = next(iter(data_loaders['test']))\n",
        "print(z.mean(), z.std())\n",
        "img_norm = z[0].permute(1, 2, 0).numpy()\n",
        "plt.imshow(img_norm)"
      ],
      "metadata": {
        "id": "He4USmY48OdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z, _ = next(iter(data_loaders['val']))\n",
        "print(z.mean(), z.std())\n",
        "img_norm = z[0].permute(1, 2, 0).numpy()\n",
        "plt.imshow(img_norm)"
      ],
      "metadata": {
        "id": "Y4YQU2vkFZes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_imgs(imgs, nrows=5, ncols=5):\n",
        "  fig, ax = plt.subplots(nrows, ncols, figsize=(nrows*5, ncols*3))\n",
        "  index = 0\n",
        "  for row in range(nrows):\n",
        "    for col in range(ncols):\n",
        "      img = matplotlib.image.imread(imgs[index][0])\n",
        "      ax[row][col].imshow(img)\n",
        "      ax[row][col].axis('off')\n",
        "      ax[row][col].set_title(imgs[index][1], fontsize=15)\n",
        "      index += 1"
      ],
      "metadata": {
        "id": "EdGiBJhu8bWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_imgs(original, img_folder=path, count=25):\n",
        "  rand_imgs = []\n",
        "  categories = original.classes\n",
        "  for cat in categories:\n",
        "    folder_path = f\"{img_folder}/{cat}\"\n",
        "    imgs_list = os.listdir(folder_path)\n",
        "    selected_imgs = np.random.choice(imgs_list, count//len(categories))\n",
        "    rand_imgs.extend([(f'{folder_path}/{img_path}', cat) for img_path in selected_imgs])\n",
        "  np.random.shuffle(rand_imgs)\n",
        "  return rand_imgs"
      ],
      "metadata": {
        "id": "31Bc5XAR8ed2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_imgs = rand_imgs(original, path, 15)"
      ],
      "metadata": {
        "id": "gpB74zRR8ebN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_imgs(my_imgs, 5, 3)"
      ],
      "metadata": {
        "id": "gOrTDI708g3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_batch(data_loader):\n",
        "  for imgs, labels in data_loader:\n",
        "    fig, ax = plt.subplots(figsize=(25, 25))\n",
        "    ax.imshow(torchvision.utils.make_grid(imgs[:60], nrow=10).permute(1, 2, 0))\n",
        "    ax.set_title('Augmented Images')\n",
        "    break"
      ],
      "metadata": {
        "id": "pcNCDEsr8inE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_batch(data_loaders['train'])"
      ],
      "metadata": {
        "id": "0KsaSKoN8iji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_batch(data_loaders['val'])"
      ],
      "metadata": {
        "id": "U_tu3Zo28iZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_batch(data_loaders['test'])"
      ],
      "metadata": {
        "id": "ldoaOhZX8n7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Train"
      ],
      "metadata": {
        "id": "PvZeiSKK8r7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds==labels).item()/len(preds)), preds"
      ],
      "metadata": {
        "id": "GLQemfWi8tFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2weights = '/content/models/'\n",
        "os.makedirs(path2weights, exist_ok=True)"
      ],
      "metadata": {
        "id": "AIP9-oOd8uS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(opt):\n",
        "  for param_group in opt.param_groups:\n",
        "    return param_group['lr']"
      ],
      "metadata": {
        "id": "WVqyy3O78uQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_epoch(model, data_loader, dataset_sizes, criterion, optimizer, scheduler, sanity_check, phase):\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "\n",
        "  for input, labels in data_loader:\n",
        "    inputs = input.to(device)\n",
        "    labels = labels.to(device)\n",
        "  \n",
        "  with torch.set_grad_enabled(phase=='train'):\n",
        "    output = model(inputs)\n",
        "    loss = criterion(output, labels)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "  if phase == 'train':\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # current_lr = get_lr(optimizer)\n",
        "    # print(optimizer)\n",
        "    # scheduler.step(loss)\n",
        "\n",
        "  # running_corrects += pred.eq(labels.view_as(pred)).sum().item()\n",
        "  running_corrects += torch.sum(pred == labels.data)\n",
        "  \n",
        "  if device == 'cpu':\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "    # running_loss += loss.item()\n",
        "  else:\n",
        "    running_loss += loss.cpu().detach().numpy()\n",
        "  \n",
        "##############################?????????????????????????????????\n",
        "  # if phase == 'train':\n",
        "  #   acc = 100 * running_corrects.double() / dataset_sizes\n",
        "  #   scheduler.step(acc)\n",
        "  \n",
        "  epoch_loss = running_loss / dataset_sizes\n",
        "  epoch_acc = running_corrects.double() / dataset_sizes\n",
        "  # return epoch_loss, epoch_acc, current_lr\n",
        "  return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "eNPG-53j8uOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val(model, params, requires_grad_param=False, trainable_layers=0):\n",
        "  \n",
        "  model_name = params['model_name']\n",
        "  num_epochs = params['epochs']\n",
        "  optimizer = params['optimizer']\n",
        "  criterion = params['criterion']\n",
        "  scheduler = params['scheduler'][0]\n",
        "  data_loaders = params['data_loaders']\n",
        "  dataset_sizes = params['dataset_sizes']\n",
        "  path2weights = params['path2weights']\n",
        "  sanity_check = params['sanity_check']\n",
        "\n",
        "  epoch_lr = 0\n",
        "  #A dictionary to save Loss's history and accuracy's history\n",
        "  loss_history = {'train': [], 'val':[]}\n",
        "  accuracy_history = {'train': [], 'val':[]}\n",
        "  lr = []\n",
        "\n",
        "  model_params_len = len(list(model.parameters()))\n",
        "  for i, param in enumerate(model.parameters()):\n",
        "    if model_params_len - i > trainable_layers:\n",
        "      param.requires_grad == requires_grad_param\n",
        "\n",
        "  model.to(device) \n",
        "  best_accuracy = 0.0\n",
        "  best_loss = float('inf')\n",
        "  best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    for phase in ['train', 'val']:\n",
        "      start = time.time()  \n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "  \n",
        "      # epoch_loss, epoch_acc, epoch_lr = loss_epoch(model, data_loaders[phase], dataset_sizes[phase], criterion, optimizer, scheduler, sanity_check, phase)\n",
        "      epoch_loss, epoch_acc = loss_epoch(model, data_loaders[phase], dataset_sizes[phase], criterion, optimizer, scheduler, sanity_check, phase)\n",
        "      # epoch_lr = get_lr(optimizer)\n",
        "      loss_history[phase].append(epoch_loss)\n",
        "      accuracy_history[phase].append(epoch_acc)\n",
        "      # lr.append(epoch_lr)\n",
        "\n",
        "      print(f'{phase.upper()} ==> Epoch: {epoch+1}/{num_epochs} - Loss: {epoch_loss}, Accuracy: {epoch_acc}, lr: {epoch_lr}')\n",
        "    \n",
        "    print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {loss_history['train'][-1]:.4f}, Train Accuracy: %{accuracy_history['train'][-1]*100:.3f}, Val Loss: {loss_history['val'][-1]:.4f}, Val Accuracy: %{accuracy_history['val'][-1]*100:.3f}\")\n",
        "\n",
        "\n",
        "    # if phase == 'val':\n",
        "    #   during = time.time() - start\n",
        "    #   print(f'Time: {during//60}m {during%60}s')\n",
        "    #   print('======'*5)\n",
        "    if phase == 'val' and epoch_loss < best_loss:\n",
        "      best_loss = epoch_loss\n",
        "      best_model = copy.deepcopy(model.state_dict())\n",
        "      torch.save(best_model, f'{path2weights}{model_name}.h5')\n",
        "      print(f'The best Model has been saved with loss: {best_loss}!!!')\n",
        "\n",
        "############################# HOOOOOOOOOOOOOOOOOOOOOOOOOw To Correct it?\n",
        "    # scheduler.step(optimizer)\n",
        "    # if lr[-1] != get_lr(optimizer):\n",
        "    #   print('loading best model weights')\n",
        "    #   model.load_state_dict(best_model)\n",
        "    # print(f\"Epoch: {epoch+1}/{num_epochs}, Train Loss: {loss_history['train'][-1]:.4f}, Train Accuracy: %{accuracy_history['train'][-1]*100:.3f}, Val Loss: {loss_history['val'][-1]:.4f}, Val Accuracy: %{accuracy_history['val'][-1]*100:.3f}\")\n",
        "    \n",
        "\n",
        "  \n",
        "  during = time.time() - start\n",
        "  print(f'{phase.upper()} ===> Time: {during//60}m {during%60}s')\n",
        "  print('======'*5)\n",
        "\n",
        "  model.load_state_dict(best_model)        \n",
        "  return model, loss_history, accuracy_history"
      ],
      "metadata": {
        "id": "XVNyoYqX80oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Models"
      ],
      "metadata": {
        "id": "jUxIWPzX832e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16"
      ],
      "metadata": {
        "id": "T-qbsawvYipS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "for param in vgg16.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "vgg16.classifier = torch.nn.Linear(in_features=vgg16.classifier[6].in_features,\n",
        "                                  out_features=len(original.classes), \n",
        "                                  bias=True)"
      ],
      "metadata": {
        "id": "Kh790ETY80lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optmizer_vgg16 = torch.optim.Adam(vgg16.classifier.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n",
        "scheduler_vgg16 = torch.optim.lr_scheduler.ReduceLROnPlateau(optmizer_vgg16, mode='max', patience=3, verbose=1)\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "params_vgg16 = {\n",
        "    'epochs': epochs,\n",
        "    'model_name': 'vgg16',\n",
        "    'data_loaders': data_loaders,\n",
        "    'criterion': torch.nn.CrossEntropyLoss(),\n",
        "    'optimizer': optimizer_vgg16,\n",
        "    'dataset_sizes': dataset_sizes,\n",
        "    'scheduler': scheduler_vgg16,\n",
        "    'path2weights': path2weights,\n",
        "    'sanity_check': True\n",
        "}"
      ],
      "metadata": {
        "id": "HmX0kTNd_m9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG19"
      ],
      "metadata": {
        "id": "lK6qlnOUYjmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg19 = torchvision.models.vgg19(pretrained=True)\n",
        "\n",
        "for param in vgg19.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "vgg19.classifier = torch.nn.Linear(in_features=vgg19.classifier[6].in_features,\n",
        "                                  out_features=len(original.classes), \n",
        "                                  bias=True)"
      ],
      "metadata": {
        "id": "R8w9L67qYlXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optmizer_vgg19 = torch.optim.Adam(vgg19.classifier.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n",
        "scheduler_vgg19 = torch.optim.lr_scheduler.ReduceLROnPlateau(optmizer_vgg19, mode='max', patience=3, verbose=1)\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "params_vgg19 = {\n",
        "    'epochs': epochs,\n",
        "    'model_name': 'vgg19',\n",
        "    'data_loaders': data_loaders,\n",
        "    'criterion': torch.nn.CrossEntropyLoss(),\n",
        "    'optimizer': optimizer_vgg19,\n",
        "    'dataset_sizes': dataset_sizes,\n",
        "    'scheduler': scheduler_vgg19,\n",
        "    'path2weights': path2weights,\n",
        "    'sanity_check': True\n",
        "}"
      ],
      "metadata": {
        "id": "5BmKpPRyYllZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inceptionv3"
      ],
      "metadata": {
        "id": "7dOds-ENZD4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionv3 = torchvision.models.inception_v3(pretrained=True)\n",
        "\n",
        "for param in inceptionv3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "inceptionv3.classifier = torch.nn.Linear(in_features=inceptionv3.fc.in_features,\n",
        "                                  out_features=len(original.classes), \n",
        "                                  bias=True)"
      ],
      "metadata": {
        "id": "je234AKcYqra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optmizer_inceptionv3 = torch.optim.Adam(inceptionv3.fc.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n",
        "scheduler_inceptionv3 = torch.optim.lr_scheduler.ReduceLROnPlateau(optmizer_inceptionv3, mode='max', patience=3, verbose=1)\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "params = {\n",
        "    'epochs': epochs,\n",
        "    'model_name': 'inceptionv3',\n",
        "    'data_loaders': data_loaders,\n",
        "    'criterion': torch.nn.CrossEntropyLoss(),\n",
        "    'optimizer': optimizer_inceptionv3,\n",
        "    'dataset_sizes': dataset_sizes,\n",
        "    'scheduler': scheduler_inceptionv3,\n",
        "    'path2weights': path2weights,\n",
        "    'sanity_check': True\n",
        "}"
      ],
      "metadata": {
        "id": "qEHPzd-5aB8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "j7zgXlvXaUFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "resnet50.classifier = torch.nn.Linear(in_features=resnet50.fc.in_features,\n",
        "                                  out_features=len(original.classes), \n",
        "                                  bias=True)"
      ],
      "metadata": {
        "id": "Q73jlWsUaHh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_resnet50 = torch.optim.Adam(resnet50.fc.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n",
        "scheduler_resnet50 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_resnet50, mode='max', patience=3, verbose=1)\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "params = {\n",
        "    'epochs': epochs,\n",
        "    'model_name': 'resnet50',\n",
        "    'data_loaders': data_loaders,\n",
        "    'criterion': torch.nn.CrossEntropyLoss(),\n",
        "    'optimizer': optimizer_resnet50,\n",
        "    'dataset_sizes': dataset_sizes,\n",
        "    'scheduler': scheduler_resnet50,\n",
        "    'path2weights': path2weights,\n",
        "    'sanity_check': True\n",
        "}"
      ],
      "metadata": {
        "id": "h2tWsJ38bFzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet B2"
      ],
      "metadata": {
        "id": "wWw4Nu42bwXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnetb2 = torchvision.models.efficientnet_b2(pretrained=True)\n",
        "\n",
        "for param in efficientnetb2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "efficientnetb2.classifier = torch.nn.Linear(in_features=efficientnetb2.classifier[1].in_features,\n",
        "                                  out_features=len(original.classes), \n",
        "                                  bias=True)"
      ],
      "metadata": {
        "id": "UcD9rAlsbx8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_efficientnetb2 = torch.optim.Adam(efficientnetb2.classifier.parameters(), lr=1e-4, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n",
        "scheduler_efficientnetb2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_efficientnetb2, mode='max', patience=3, verbose=1)\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "params = {\n",
        "    'epochs': epochs,\n",
        "    'model_name': 'efficientnetb2',\n",
        "    'data_loaders': data_loaders,\n",
        "    'criterion': torch.nn.CrossEntropyLoss(),\n",
        "    'optimizer': optimizer_efficientnetb2,\n",
        "    'dataset_sizes': dataset_sizes,\n",
        "    'scheduler': scheduler_efficientnetb2,\n",
        "    'path2weights': path2weights,\n",
        "    'sanity_check': True\n",
        "}"
      ],
      "metadata": {
        "id": "rxnsMkDPcc7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}